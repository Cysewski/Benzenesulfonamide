{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca32f23b-29c9-4066-b594-66f9a401f07a",
   "metadata": {},
   "source": [
    "# Optuna Meta-model (tuned ensemble of regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d82ebe-5e1f-43f9-8511-0148ddcbe50b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c3a91d-a1e4-4ab1-91fe-99e44757fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; import pandas as pd; import matplotlib.pyplot as plt;\n",
    "import os; import joblib; \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# models\n",
    "model_names = ['AdaBoostRegressor', 'ARDRegression', 'BaggingRegressor','BayesianRidge',\n",
    "               'DecisionTreeRegressor','DummyRegressor','ElasticNet','ElasticNetCV',\n",
    "               'ExtraTreeRegressor','GradientBoostingRegressor','GaussianProcessRegressor','HistGradientBoostingRegressor',               \n",
    "               'HuberRegressor', 'KNeighborsRegressor','Lars','LarsCV',\n",
    "               'Lasso','LassoLars','LassoLarsCV','LassoLarsIC',\n",
    "               'LinearSVR','MLPRegressor','NuSVR','OrthogonalMatchingPursuit',\n",
    "               'OrthogonalMatchingPursuitCV','PassiveAggressiveRegressor','RANSACRegressor','Ridge',\n",
    "               'RandomForestRegressor', 'SGDRegressor','SVR','TheilSenRegressor',\n",
    "               'TransformedTargetRegressor','XGBRegressor','LGBMRegressor','CatBoostRegressor']\n",
    "\n",
    "from sklearn.linear_model import ARDRegression, BayesianRidge, ElasticNet, ElasticNetCV, Lasso, LassoLarsIC,Lars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV, RANSACRegressor,TheilSenRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LarsCV, Ridge, LassoLars\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342ecb4-998b-47a5-94a9-9d4a54d31d7f",
   "metadata": {},
   "source": [
    "# 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b583e7-45f0-4977-b0bb-0cb8dd3d2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      " Benzenesulfonamide \n",
      "solubility meta model \n",
      "-------------------\n",
      "Dataset: 190 measurements\n",
      "Screening: 1698 solvents\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_file=\"data.xlsx\"\n",
    "data_exp_sheet=\"dataset\"\n",
    "data_ext_sheet=\"solvents\"\n",
    "data_MetaModel_sheet='meta model'\n",
    "predictions_file=\"predictions.xlsx\"\n",
    "# name of independent value\n",
    "Yname='log(x1)exp'\n",
    "print('------------------')\n",
    "print(' Benzenesulfonamide ')\n",
    "print('solubility meta model ')\n",
    "print('-------------------')\n",
    "YX=pd.read_excel('.//'+data_file,sheet_name=data_exp_sheet,usecols=\"F:J\")\n",
    "XX=YX.drop(YX.columns[0], axis=1)\n",
    "Y=YX[Yname]\n",
    "extXX=pd.read_excel('.//'+data_file,sheet_name=data_ext_sheet,usecols=\"F:I\")\n",
    "print('Dataset:',len(Y),'measurements')\n",
    "print('Screening:',len(extXX),'solvents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32eef5fd-9e92-47bf-bf8c-db0c512eebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting and standarization\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(XX, Y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)\n",
    "# Scale the data: standardize all data subsets\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_val_std = scaler.transform(X_val)\n",
    "XX_std = scaler.transform(XX)\n",
    "extXX_std=scaler.transform(extXX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc1663-d3ad-4d3e-91c4-ee037efe8d8b",
   "metadata": {},
   "source": [
    "# 3. Models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f294d75-5f22-4db8-9b5a-2e534af69923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AdaBoostRegressor: train set: [mse=0.014] test set: [mse=0.025 ]  validation set: [mse=0.019 ]\n",
      "2. ARDRegression: train set: [mse=0.026] test set: [mse=0.027 ]  validation set: [mse=0.018 ]\n",
      "3. BaggingRegressor: train set: [mse=0.003] test set: [mse=0.018 ]  validation set: [mse=0.010 ]\n",
      "4. BayesianRidge: train set: [mse=0.026] test set: [mse=0.027 ]  validation set: [mse=0.018 ]\n",
      "5. CatBoostRegressor: train set: [mse=0.292] test set: [mse=0.359 ]  validation set: [mse=0.269 ]\n",
      "6. DecisionTreeRegressor: train set: [mse=0.016] test set: [mse=0.029 ]  validation set: [mse=0.030 ]\n",
      "7. DummyRegressor: train set: [mse=0.370] test set: [mse=0.382 ]  validation set: [mse=0.209 ]\n",
      "8. ElasticNet: train set: [mse=0.030] test set: [mse=0.032 ]  validation set: [mse=0.018 ]\n",
      "9. ElasticNetCV: train set: [mse=2.199] test set: [mse=2.247 ]  validation set: [mse=2.110 ]\n",
      "10. ExtraTreeRegressor: train set: [mse=0.016] test set: [mse=0.028 ]  validation set: [mse=0.016 ]\n",
      "11. GaussianProcessRegressor: train set: [mse=0.026] test set: [mse=0.027 ]  validation set: [mse=0.018 ]\n",
      "12. GradientBoostingRegressor: train set: [mse=0.001] test set: [mse=0.009 ]  validation set: [mse=0.006 ]\n",
      "13. HistGradientBoostingRegressor: train set: [mse=0.012] test set: [mse=0.023 ]  validation set: [mse=0.017 ]\n",
      "14. HuberRegressor: train set: [mse=0.026] test set: [mse=0.027 ]  validation set: [mse=0.019 ]\n",
      "15. KNeighborsRegressor: train set: [mse=0.000] test set: [mse=0.015 ]  validation set: [mse=0.010 ]\n",
      "16. Lars: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.018 ]\n",
      "17. LarsCV: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.018 ]\n",
      "18. Lasso: train set: [mse=0.030] test set: [mse=0.035 ]  validation set: [mse=0.014 ]\n",
      "19. LassoLars: train set: [mse=0.030] test set: [mse=0.035 ]  validation set: [mse=0.014 ]\n",
      "20. LassoLarsCV: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.018 ]\n",
      "21. LassoLarsIC: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.018 ]\n",
      "22. LGBMRegressor: train set: [mse=0.015] test set: [mse=0.020 ]  validation set: [mse=0.015 ]\n",
      "23. LinearSVR: train set: [mse=0.033] test set: [mse=0.039 ]  validation set: [mse=0.021 ]\n",
      "24. MLPRegressor: train set: [mse=0.000] test set: [mse=0.000 ]  validation set: [mse=0.002 ]\n",
      "25. NuSVR: train set: [mse=0.006] test set: [mse=0.006 ]  validation set: [mse=0.005 ]\n",
      "26. OrthogonalMatchingPursuit: train set: [mse=0.026] test set: [mse=0.027 ]  validation set: [mse=0.018 ]\n",
      "27. OrthogonalMatchingPursuitCV: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.019 ]\n",
      "28. PassiveAggressiveRegressor: train set: [mse=6.937] test set: [mse=4.148 ]  validation set: [mse=4.569 ]\n",
      "29. RandomForestRegressor: train set: [mse=0.005] test set: [mse=0.014 ]  validation set: [mse=0.010 ]\n",
      "30. RANSACRegressor: train set: [mse=0.073] test set: [mse=0.075 ]  validation set: [mse=0.018 ]\n",
      "31. Ridge: train set: [mse=0.026] test set: [mse=0.028 ]  validation set: [mse=0.018 ]\n",
      "32. SGDRegressor: train set: [mse=0.027] test set: [mse=0.032 ]  validation set: [mse=0.018 ]\n",
      "33. SVR: train set: [mse=0.008] test set: [mse=0.021 ]  validation set: [mse=0.013 ]\n",
      "34. TheilSenRegressor: train set: [mse=2.253] test set: [mse=2.211 ]  validation set: [mse=2.062 ]\n",
      "35. TransformedTargetRegressor: train set: [mse=0.046] test set: [mse=0.062 ]  validation set: [mse=0.014 ]\n",
      "[07:44:29] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "36. XGBRegressor: train set: [mse=0.010] test set: [mse=0.015 ]  validation set: [mse=0.014 ]\n",
      "All models were loaded sucesfully:\n"
     ]
    }
   ],
   "source": [
    "regressors_pd=pd.read_excel('.//'+data_file,sheet_name=data_MetaModel_sheet,usecols=\"A,B\")\n",
    "# Load models from disk\n",
    "models = []\n",
    "models_loaded = []\n",
    "i=0\n",
    "for name in regressors_pd['Regressor']:\n",
    "    file=\".//models//\" + \"model_\"+ name + \".pkl\"\n",
    "    if os.path.exists(file):\n",
    "        model=joblib.load(file)\n",
    "        models.append(model)\n",
    "        y_train_pred = model.predict(X_train_std)\n",
    "        y_test_pred = model.predict(X_test_std)\n",
    "        y_val_pred = model.predict(X_val_std)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "        loaded=[i,name,mse_test,model]\n",
    "        models_loaded.append(loaded)\n",
    "        extY_pred = model.predict(extXX_std)\n",
    "        i=i+1\n",
    "        print(f\"{i}. {name}: train set: [mse={mse_train:.3f}] test set: [mse={mse_test:.3f} ]  validation set: [mse={mse_val:.3f} ]\")  \n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Model file {file} does not exist.\")\n",
    "\n",
    "if len(model_names)==len(models):\n",
    "    print(\"All models were loaded sucesfully:\")\n",
    "else:\n",
    "    print(\"There are still missing some models:\", 34-len(models))\n",
    "N_models=i    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bff8a6-d6da-47b2-af1b-917bb2e84476",
   "metadata": {},
   "source": [
    "# 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88ade2b5-b8bf-4633-b3d7-b33e7da052d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      " Predicted benzenesulfonamide solubiliy \n",
      "     in the foloowing solvents\n",
      "    (logarithm of mole fraction)\n",
      "------------------------------------------------\n",
      "DMSO -0.58\n",
      "DMF -0.62\n",
      "Morpholine-4-carbaldehyde -1.06\n",
      "n-Pentanol -1.95\n",
      "pyrimidine -0.62\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "newXX=pd.read_excel('.//'+predictions_file,usecols=\"C:F\")\n",
    "newSolvents=pd.read_excel('.//'+predictions_file,usecols=\"A\")\n",
    "newXX_std=scaler.transform(newXX)\n",
    "newY_pred = np.zeros(newXX_std.shape[0])\n",
    "for i  in range(N_models):\n",
    "    name=regressors_pd['Regressor'][i]\n",
    "    weight=regressors_pd['weight'][i]\n",
    "    model=models[i]\n",
    "    newY_pred += weight * model.predict(newXX_std)\n",
    "newY_pred_df = pd.DataFrame(index=range(len(newY_pred))) \n",
    "newY_pred_df['meta model']=newY_pred.reshape((-1, 1))\n",
    "newY_pred_df = pd.concat([newSolvents,newY_pred_df], axis=1)\n",
    "print('------------------------------------------------')\n",
    "print(' Predicted benzenesulfonamide solubiliy ')\n",
    "print('     in the foloowing solvents')\n",
    "print('    (logarithm of mole fraction)')\n",
    "print('------------------------------------------------')\n",
    "for i in range(len(newY_pred_df)):\n",
    "    print(f\"{newY_pred_df['solvent'][i]} {newY_pred_df['meta model'][i]:.2f}\" )\n",
    "print('------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Molecular descriptors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
